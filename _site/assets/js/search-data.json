{
  "0": {
    "id": "0",
    "title": "",
    "content": "404 Page not found :( The requested page could not be found.",
    "url": "http://localhost:4000/404.html",
    "relUrl": "/404.html"
  },
  "1": {
    "id": "1",
    "title": "About",
    "content": "Olá, me chamo Giancarlo, mas você pode me chamar de Gian. Eu sou apaixonado por machine learning e processamento de linguagem natural (PLN), especialmente language models e neural machine translation. Eu também gosto muito de deep learning, Pokemón Go (giancds mystic lvl. 40) e levantamento de peso olímpico. Eu leio bastante sobre tudo, não sei nadar, posso beber até 7 xícaras de café em um dia e sou um péssimo piadista. Fiz meu doutorado em Ciência da Computação com ênfase em machine learning aplicado a PLN no Dublin Institute of Technology - DIT (hoje Technological University Dublin - TUD) na Irlanda, sob orientação do Prof. John D. Kelleher e do Dr. Robert J. Ross. Também fiz pós-doutorado em deep learning aplicado a language models no ADAPT Centre na Irlanda sob supervisão do Prof. John D. Kelleher. Aqui você encontra uma lista atualizada de minhas publicações, tanto em Inglês quanto em Português.",
    "url": "http://localhost:4000/about/",
    "relUrl": "/about/"
  },
  "2": {
    "id": "2",
    "title": "",
    "content": "",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },
  "3": {
    "id": "3",
    "title": "Introdução ao Machine Learning",
    "content": "1 - Introdução Machine Learning é a disciplina da Inteligência Artificial a qual estuda a criação de agentes inteligentes que aprendem através da experiência. Desta forma, ao contrário da Inteligência Artificial clássica, o agente inteligente não tem seu conhecimento programado durante sua criação, mas ele é programado para aprender a alcançar o objetivo para o qual foi desenvolvido. Embora alguns autores definam machine learning como sendo o aprendizado através de exemplos, esta definição exclui o aprendizado por reforço positivo1 (do Inglês Reinforcement Learning - RL) onde o agente aprende praticando a tarefa sem quaisquer tipos de respostas, recebendo apenas um feedback sobre o quão bem está executando aquela tarefa. A definição de aprendizado através de exemplos é mais adequada às áreas de machine learning supervisionado e machine learning não-supervisionado (ou sem supervisão). O machine learning supervisionado envolve o aprendizado de um modelo que descreve as relações entre um conjunto de variáveis descritivas (também chamadas de features) e uma variável alvo (também chamada de target). Esta forma de machine learning gera modelos que podem ser aplicados a dois tipos de problemas:     i. regressão prever um target contínuo     ii. regressão prever um target categórico Devido ao fato de o modelo aprendido em machine learning descrever as relações entre features e targets, é necessário o levantamento de um conjunto de dados (também chamado de dataset) que contenha exemplos (também chamados de datapoints) com os valores das features preenchidas e o target correto associado àquelas features. Por padrão, um dataset segue o formato apresentado na Tabela 1. begin{table}[t] caption{Formato de um emph{dataset}. Por padrão, emph{features} ficam nas colunas à esquerda enquanto o emph{target} é colocado na última coluna mais à direita. Cada linha do emph{dataset} corresponde a um emph{datapoint} (i.e., as emph{features} e o emph{target} correspondente a um exemplo).} small centering setlength tabcolsep{12pt} begin{tabular}{0.6 textwidth}{c c c c c c c c} toprule multicolumn{6}{c}{ features} &amp; &amp; target cmidrule{1-6} cmidrule{8-8} &amp; &amp; &amp; &amp; &amp; &amp; &amp; midrule — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; — — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; — — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; — — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; — — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; — — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; — — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; — bottomrule end{tabular} label{tab:features} end{table} A Tabela 2 apresenta um exemplo de um dataset real. Esta é uma amostra do dataset Iris publicado em 1953 e que até hoje representa um caso típico de testes para modelos de machine learning. begin{table}[th] caption{Amostra do clássico dataset myquote{Iris} para demonstrar um exemplo de dataset com exemplos reais. O myquote{Iris} foi introduzido por Ronald Fisher em 1936 e tornou-se um caso de teste típico para algoritmos de ml. O dataset é constituído por quatro features ( featN{sepal length}, featN{sepal width}, featN{petal length} e featN{petal width}) e um target ( featN{species})} centering small setlength tabcolsep{10pt} begin{tabular}{0.58 textwidth}{c c c c c c} toprule featN{} &amp; featN{sepal} &amp; featN{sepal} &amp; featN{petal} &amp; featN{petal} &amp; featN{species} featN{ID} &amp; featN{length} &amp; featN{width} &amp; featN{length} &amp; featN{width} &amp; ( target) midrule 1 &amp; 5.1 &amp; 3.5 &amp; 1.4 &amp; 0.2 &amp; setosa 2 &amp; 4.9 &amp; 3.0 &amp; 1.4 &amp; 0.2 &amp; setosa 3 &amp; 4.7 &amp; 3.2 &amp; 1.3 &amp; 0.2 &amp; setosa 4 &amp; 7.0 &amp; 3.2 &amp; 4.7 &amp; 1.4 &amp; versicolor 5 &amp; 6.4 &amp; 3.2 &amp; 4.5 &amp; 1.5 &amp; versicolor 6 &amp; 6.9 &amp; 3.1 &amp; 4.9 &amp; 1.5 &amp; versicolor 7 &amp; 6.3 &amp; 3.3 &amp; 6.0 &amp; 2.5 &amp; virginica 8 &amp; 5.8 &amp; 2.7 &amp; 5.1 &amp; 1.9 &amp; virginica 9 &amp; 7.1 &amp; 3.0 &amp; 5.9 &amp; 2.1 &amp; virginica midrule &amp; &amp; &amp; &amp; &amp; bottomrule end{tabular} label{tab:iris} end{table} Abaixo seguem algumas definições importantes que são utilizadas em machine learning:     i. Features (ou variáveis descritivas): conjunto de informações relativos a um exemplo domínio     ii. Target (ou variável alvo): resposta correta relativa a um exemplo do domínio     iii. Datapoint (ou exemplo): features + target     iv. Query: um datapoint para o qual queremos predizer o target correto (i.e., um datapoint sem target associado)     v. Dataset (ou conjunto de exemplos): conjunto de datapoints     vi. algoritmo: processo utilizado para aprender o modelo     vii. modelo: conjunto de “regras” aprendidas             O modelo é o Agente Inteligente! A Figura 1 ilustra o processo de “aprendizado” de machine learning. Um dataset contendo features e targets é fornecido como entrada para um algoritmo que por sua vez gera um modelo. Depois que o modelo for gerado, podemos pegar uma query e obter uma predição para determinar qual a resposta (i.e., o target) correta para aquela instância. A Figura 2 ilustra o processo de predição. 1.1 - Um pequeno exemplo Suponhamos que o dataset contido na Tabela 3 nos foi fornecido e precisamos extrair manualmente um modelo para fazer predições. Qual(is) a(s) regra(s) que definem as relações entre features e target deste dataset? Após alguma análise, podemos propor o algoritmo abaixo (demonstrado utilizando a linguagem python): if Proporção Salário-Empréstimo &lt; 1.5: Classe = &#39;Padrão&#39; else: Classe=&#39;diferenciada&#39; Bastante simples, não? Este é um exemplo de um modelo de predições (ou seja, exemplo de um agente inteligente). Este é também um exemplo de um modelo consistente com o dataset. Um modelo consistente com o dataset é aquele que depois de aprendido consegue classificar os datapoints contidos no dataset com 100% de acurácia (i.e., sem cometer erros). Observe também que o modelo não faz uso de todas as features apresentadas e que a feature utilizada é uma feature derivada2. Uma feature derivada é uma feature que pode ser obtida a partir de duas ou mais features. No exemplo do modelo acima, Proporção Salário-Empréstimo pode ser obtida através de features Salário e Empréstimo (que não foram exibidas na tabela). Agora, vamos dificultar as coisas. Suponhamos o dataset contido na Tabela 4. INCLUIR TABELA Após uma análise minuciosa deste dataset, podemos propor o algoritmo abaixo (demonstrado utilizando a linguagem python): if Proporção Salário-Empréstimo &lt; 1.5: classe = &#39;diferenciada&#39; elif Proporção Salário-Empréstimo &gt; 4: classe =&#39;padrão&#39; elif idade &lt; 40 and profissão == &#39;indústria&#39;: classe = &#39;padrão&#39; else: classe = &#39;diferenciada&#39; De certa maneira, a extração das regras ficou mais complicada. Imaginemos o caso de um dataset com dezenas de features e milhares de datapoints. A tarefa de extrair as regras torna-se quase que humanamente impossível de realizar. São nestes casos mais complexos que o “brilho” do machine learning aparece. Enquanto para nós seres humanos a tarefa deve certamente demorar dias ou mesmo semanas, um computador pode gerar um modelo em poucos minutos! 2 - Como o machine learning funciona O aprendizado de um modelo de machine learning pode ser visto como um processo de busca. Este processo conduz uma busca pelo modelo que melhor captura as relações entre as features e o target. Ou seja, busca pelo modelo capaz de gerar predições corretas para query que ele recebe como entrada. A forma mais fácil e eficaz para gerar um modelo é buscar dentre os modelos possíveis por aqueles modelos que sejam “consistentes” com os datapoints. No entanto, para maioria dos casos, um dataset é apenas uma amostra do número total de datapoints possíveis quando consideramos as possibilidades de combinações dos valores das features. Por exemplo: se uma das features for contínua, temos uma infinita possibilidade de combinações! Por isso, dizemos que o machine learning é um problema mal-posto. Vamos ilustrar a ideia de consistência e imperfeição com um exemplo. Imaginemos que uma rede de supermercados nos contratou para desenvolver um modelo de machine learning para realizar predições sobre seus consumidores. Estas predições devem classificar os consumidores nos grupos Famílias, Casais sem filhos e Solteiros. Esta rede de supermercados está disposta a lhe entregar um dataset com três features binárias que podem assumir os valores . Como três features binárias produzem um total de combinações, antes de olharmos para o dataset decidimos construir uma tabela com todas as possíveis combinações destas features. Estas combinações estão reproduzidas na Tabela 5. INCLUIR TABELA Quando passamos a considerar os valores para o Grupo sem termos recebido os valores corretos para o target de cada datapoint, o número de combinações diferentes para o dataset sobe para 6561! A partir dessas combinações que consideram o target, podemos procurar por uma combinação que possa servir como modelo para fazer predições sobre os consumidores do mercado. Uma amostra destas combinações está disponível na Tabela 6. INCLUIR TABELA Suponhamos então que a rede de supermercados conduziu uma pesquisa entre seus consumidores e que o número de respostas obtido foi baixo. Apenas cinco datapoints foram obtidos conforme demonstrado na Tabela 7. Se considerarmos os datapoints obtidos pela rede de supermercados, podemos eliminar combinações as quais possuem o target Grupo diferentes dos valores reais obtidos, como demonstrado na Tabela 8. As combinações restantes são aquelas chamadas de consistentes com o dataset da Tabela 7. Em outras palavras, estas combinações restantes conseguem produzir a resposta correta para cada datapoint do dataset. Entretanto, ainda temos um problema: das 8 possíveis combinações das features binárias, apenas 5 foram obtidas e, por isso, temos três combinações que nunca foram vistas! Se olharmos novamente para a Tabela 8, as combinações , e são combinações consistentes com o dataset e ao mesmo tempo divergem quanto ao Grupo que deve ser atribuído aos três casos que não foram vistos. Qual destas três combinações devemos escolher como sendo o modelo final? É exatamente pelo fato de podermos obter mais de um modelo consistente com o dataset que dizemos que o machine learning é um problema mal-posto, pois não há uma solução para esse problema! Consistência pode ser interpretada como uma forma de memorização por parte do modelo. Contudo, os datapoints em um dataset podem conter diversas formas de ruídos, como por exemplo preenchimentos incorretos de valores, valores faltando, até mesmo exceções onde o valor é de fato correto mas tão incomum que parece estar incorreto. Nestes casos, a memorização torna-se uma característica indesejada para um modelo de machine learning. Ao mesmo tempo que buscamos um modelo consistente, procuramos também um modelo que seja capaz de generalizar além dos dados. Um modelo com esta característica é capaz de fazer predições corretas mesmo na presença de datapoints com ruído. Ou seja, este modelo que é capaz de generalizar além do dataset não é influenciado pelo ruído nos dados. Sendo assim, que critérios devemos utilizar para selecionar este modelo? O machine learning faz uma série de suposições que auxiliam a definir os critérios de seleção de um modelo. Estas suposições são chamados viéses indutivos (do Inglês inductive bias):     a.viés de restrição (restriction bias): limita o tipo de modelo que será aprendido.     b. viés de preferência (preference bias): limita o algoritmo para que prefira alguns tipos de modelo em detrimento a outros modelos. Por exemplo, consideremos o Iterative Dichotomizer 3 - (ID3), o algoritmo padrão para métodos baseados em informação3. Este algoritmo possui um restriction bias que o limita a aprender um modelo em formato de árvore que codifica em cada galho um “teste” em uma determinada feature enquanto o seu preference bias limita-o a buscar pela árvore que contenha o menor número possível de níveis. 2.1 - O que pode dar errado com o machine learning? Até agora vimos que o machine learning pode ser bastante útil para criarmos agentes inteligentes que podem ser úteis em alguns tipos de problemas. Vimos também que devido ao efeito do inductive bias, modelos podem aprender a generalizar além do dataset. No entanto, se escolhermos o inductive bias errado, o modelo aprendido poderá apresentar dois tipos de problemas: underfitting e overfitting. Underfitting ocorre quando o modelo aprendido através do inductive bias é muito simples para capturar as relações entre features e targets. Overfitting, ao contrário, ocorre quando o modelo aprendido através do inductive bias é demasiado complexo para capturar as relações entre features e targets. A Figura 3 exibe um exemplo de underfitting e overfitting. 3 - Resumo Em resumo, um algoritmo de machine learning aprende a relação entre features e targets a partir de exemplos contidos em um dataset. Além disso, machine learning é considerado um problema malposto devido a quatros fatores: a) precisa generalizar a além do dataset que por sua vez é apenas uma amostra; b) precisa de um conjunto de suposições que são necessárias para o aprendizado (inductive bias); c) underfitting; e d) overfitting. Encontrar o balanço entre complexidade e simplicidade é uma forma de arte do machine learning e, também, a parte mais difícil de prática.",
    "url": "http://localhost:4000/docs/machine_learning/intro_ml.tex.html",
    "relUrl": "/docs/machine_learning/intro_ml.tex.html"
  },
  "4": {
    "id": "4",
    "title": "Machine Learning",
    "content": "Nesta seção, irei publicar alguns artigos sobre machine learning e deep lerning, incluindo notas de aula, resumos e tutoriais.",
    "url": "http://localhost:4000/docs/machine_learning",
    "relUrl": "/docs/machine_learning"
  },
  "5": {
    "id": "5",
    "title": "Publicações",
    "content": "Note que as publicações mais recentes estão disponíveis apenas em Inglês.",
    "url": "http://localhost:4000/docs/publications.html",
    "relUrl": "/docs/publications.html"
  }
  
}
