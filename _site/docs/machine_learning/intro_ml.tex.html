<!DOCTYPE html>

<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  
    <title>Introdução ao Machine Learning - Blog do Gian</title>

    
  

  <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="http://localhost:4000/assets/css/just-the-docs.css">

  

  
  <script type="text/javascript" src="http://localhost:4000/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Introdução ao Machine Learning | Blog do Gian</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Introdução ao Machine Learning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Eu escrevo sobre inteligência artificial, machine learning, deep learning e ciência de dados em geral." />
<meta property="og:description" content="Eu escrevo sobre inteligência artificial, machine learning, deep learning e ciência de dados em geral." />
<link rel="canonical" href="http://localhost:4000/docs/machine_learning/intro_ml.tex.html" />
<meta property="og:url" content="http://localhost:4000/docs/machine_learning/intro_ml.tex.html" />
<meta property="og:site_name" content="Blog do Gian" />
<script type="application/ld+json">
{"url":"http://localhost:4000/docs/machine_learning/intro_ml.tex.html","description":"Eu escrevo sobre inteligência artificial, machine learning, deep learning e ciência de dados em geral.","@type":"WebPage","headline":"Introdução ao Machine Learning","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body>

  <div class="page-wrap">
    <div class="side-bar">
      <a href="http://localhost:4000" class="site-title fs-6 lh-tight">Blog do Gian</a>
      <span class="fs-3"><button class="js-main-nav-trigger navigation-list-toggle btn btn-outline" type="button" data-text-toggle="Hide">Menu</button></span>
      <div class="navigation main-nav js-main-nav">
        <nav role="navigation" aria-label="Main navigation">
  <ul class="navigation-list">
    
    
      
        
          <li class="navigation-list-item active">
            
            <a href="http://localhost:4000/404.html" class="navigation-list-link"></a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/about/" class="navigation-list-link">About</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/publications.html" class="navigation-list-link">Publicações</a>
                      
                    </li>
                  
                
              </ul>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item active">
            
            <a href="http://localhost:4000/" class="navigation-list-link"></a>
            
          </li>
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item active">
            
            <a href="http://localhost:4000/docs/machine_learning" class="navigation-list-link">Machine Learning</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item  active">
                      
                      <a href="http://localhost:4000/docs/machine_learning/intro_ml.tex.html" class="navigation-list-link active">Introdução ao Machine Learning</a>
                      
                    </li>
                  
                
                  
                
                  
                
              </ul>
            
          </li>
        
      
    
      
        
      
    
  </ul>
</nav>

      </div>
      <footer role="contentinfo" class="site-footer">
        <p class="text-small text-grey-dk-000 mb-0">This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</p>
      </footer>
    </div>
    <div class="main-content-wrap js-main-content" tabindex="0">
      <div class="page-header">
        <div class="main-content">
          
          
        </div>
      </div>
      <div class="main-content">
        
          
            <nav class="breadcrumb-nav">
              <ol class="breadcrumb-nav-list">
                
                  <li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/machine_learning">Machine Learning</a></li>
                
                <li class="breadcrumb-nav-list-item"><span>Introdução ao Machine Learning</span></li>
              </ol>
            </nav>
          
        
        <div id="main-content" class="page-content" role="main">
          <h2 id="1---introdução">1 - Introdução</h2>

<p><em>Machine Learning</em> é a disciplina da Inteligência Artificial a qual estuda a criação de <strong>agentes inteligentes</strong> que aprendem através da experiência. Desta forma, ao contrário da Inteligência Artificial clássica, o agente inteligente não tem seu conhecimento programado durante sua criação, mas ele é <strong>programado para aprender</strong> a alcançar o objetivo para o qual foi desenvolvido.</p>

<p>Embora alguns autores definam <em>machine learning</em> como sendo o <strong>aprendizado através de exemplos</strong>, esta definição exclui o aprendizado por reforço positivo<sup>1</sup> (do Inglês <em>Reinforcement Learning - RL</em>) onde o agente aprende praticando a tarefa sem quaisquer tipos de respostas, recebendo apenas um <em>feedback</em> sobre o quão bem está executando aquela tarefa. A definição de aprendizado através de exemplos é mais adequada às áreas de <strong>machine learning supervisionado</strong>  e machine learning não-supervisionado (ou sem supervisão).</p>

<p>O <em>machine learning</em> supervisionado envolve o aprendizado de um modelo que descreve as relações entre um conjunto de <strong>variáveis descritivas</strong> (também chamadas de <strong><em>features</em></strong>) e uma <strong>variável alvo</strong> (também chamada de <strong><em>target</em></strong>). Esta forma de <em>machine learning</em> gera modelos que podem ser aplicados a dois
tipos de problemas:</p>

<p>    i. <strong>regressão</strong> $\rightarrow$ prever um <em>target</em> contínuo</p>

<p>    ii. <strong>regressão</strong> $\rightarrow$ prever um <em>target</em> categórico</p>

<p>Devido ao fato de o modelo aprendido em <em>machine learning</em> descrever as relações entre <em>features</em> e <em>targets</em>, é necessário o levantamento de um conjunto de dados (também chamado de <em>dataset</em>) que contenha exemplos (também chamados de <em>datapoints</em>) com os valores das <em>features</em> preenchidas e o <em>target</em> correto associado àquelas <em>features</em>. Por padrão, um dataset segue o formato apresentado na Tabela 1.</p>

<p>\begin{table<em>}[t]
  \caption{Formato de um \emph{dataset}. Por padrão, \emph{features} ficam nas colunas à esquerda enquanto o \emph{target} é colocado na última coluna mais à direita. Cada linha do \emph{dataset} corresponde a um \emph{datapoint} (i.e., as \emph{features} e o \emph{target} correspondente a um exemplo).}
  \small
  \centering
  \setlength\tabcolsep{12pt}
  \begin{tabular</em>}{0.6\textwidth}{c c c c c c c c}
  \toprule  <br />
    \multicolumn{6}{c}{\features} &amp; &amp; \target <br />
      \cmidrule{1-6}  \cmidrule{8-8}
    $x_1$  &amp; $x_2$ &amp; $x_3$ &amp; $x_4$ &amp; $x_5$ &amp; $x_6$ &amp; &amp; $y$ <br />
  \midrule
  — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; —	\<br />
  — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; —	\<br />
  — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; —	\<br />
  — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; —	\<br />
  — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; —	\<br />
  — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; —	\<br />
  — &amp; — &amp; — &amp; — &amp; — &amp; — &amp; &amp; —	<br />
  \bottomrule<br />
  \end{tabular<em>}
  \label{tab:features}
\end{table</em>}</p>

<p>A Tabela 2 apresenta um exemplo de um <em>dataset</em> real. Esta é uma amostra do dataset <em>Iris</em> publicado em 1953 e que até hoje representa um caso típico de testes para modelos de <em>machine learning</em>.</p>

<p>\begin{table}[th]
  \caption{Amostra do clássico \dataset \myquote{Iris} para demonstrar um exemplo de \dataset com exemplos reais. O \myquote{Iris} foi introduzido por Ronald Fisher em 1936 e tornou-se um caso de teste típico para algoritmos de \ml. O \dataset é constituído por quatro \features (\featN{sepal length}, \featN{sepal width}, \featN{petal length} e \featN{petal width}) e um \target (\featN{species})}
  \centering
  \small
  \setlength\tabcolsep{10pt}
  \begin{tabular<em>}{0.58\textwidth}{c c c c c c}
  \toprule
    \featN{}	 &amp; \featN{sepal}	&amp; \featN{sepal} &amp; \featN{petal} &amp; \featN{petal} &amp; \featN{species}<br />
    \featN{ID}	 &amp; \featN{length}	&amp; \featN{width} &amp; \featN{length} &amp; \featN{width} &amp; (\target)<br />
  \midrule
  1 &amp; 5.1 &amp; 3.5 &amp; 1.4 &amp; 0.2 &amp; setosa <br />
  2 &amp; 4.9 &amp; 3.0 &amp; 1.4 &amp; 0.2 &amp; setosa <br />
  3 &amp; 4.7 &amp; 3.2 &amp; 1.3 &amp; 0.2 &amp; setosa <br />
  4 &amp; 7.0 &amp; 3.2 &amp; 4.7 &amp; 1.4 &amp; versicolor <br />
  5 &amp; 6.4 &amp; 3.2 &amp; 4.5 &amp; 1.5 &amp; versicolor \ 
  6 &amp; 6.9 &amp; 3.1 &amp; 4.9 &amp; 1.5 &amp; versicolor <br />
  7 &amp; 6.3 &amp; 3.3 &amp; 6.0 &amp; 2.5 &amp; virginica <br />
  8 &amp; 5.8 &amp; 2.7 &amp; 5.1 &amp; 1.9 &amp; virginica <br />
  9 &amp; 7.1 &amp; 3.0 &amp; 5.9 &amp; 2.1 &amp; virginica <br />
  \midrule
    &amp; $x_1$ &amp; $x_2$ &amp; $x_3$ &amp; $x_4$ &amp; $y$ <br />
  \bottomrule
  \end{tabular</em>}
  \label{tab:iris}
\end{table}</p>

<p>Abaixo seguem algumas definições importantes que são utilizadas em machine learning:</p>

<p>    i. <strong>Features</strong> (ou variáveis descritivas): conjunto de informações relativos a um exemplo domínio</p>

<p>    ii. <strong>Target</strong> (ou variável alvo): resposta correta relativa a um exemplo do domínio</p>

<p>    iii. <strong>Datapoint</strong> (ou exemplo): features + target</p>

<p>    iv. <strong>Query</strong>: um datapoint para o qual queremos predizer o target correto (i.e., um datapoint sem target associado)</p>

<p>    v. <strong>Dataset</strong> (ou conjunto de exemplos): conjunto de datapoints</p>

<p>    vi. <strong>algoritmo</strong>: processo utilizado para aprender o modelo</p>

<p>    vii. <strong>modelo</strong>: conjunto de “regras” aprendidas</p>

<p>            <strong>O modelo é o Agente Inteligente!</strong></p>

<p>A Figura 1 ilustra o processo de “aprendizado” de <em>machine learning</em>. Um <em>dataset</em> contendo <em>features</em> e <em>targets</em> é fornecido como entrada para um algoritmo que por sua vez gera um modelo. Depois que o modelo for gerado, podemos pegar uma <em>query</em> e obter uma predição para determinar qual a resposta (i.e., o <em>target</em>) correta para aquela instância. A Figura 2 ilustra o processo de predição.</p>

<h3 id="11---um-pequeno-exemplo">1.1 - Um pequeno exemplo</h3>

<p>Suponhamos que o <em>dataset</em> contido na Tabela 3 nos foi fornecido e precisamos extrair manualmente um modelo para fazer predições. Qual(is) a(s) regra(s) que definem as relações entre <em>features</em> e <em>target</em> deste dataset?</p>

<p>Após alguma análise, podemos propor o algoritmo abaixo (demonstrado utilizando a linguagem <em>python</em>):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">Propor</span><span class="err">çã</span><span class="n">o</span> <span class="n">Sal</span><span class="err">á</span><span class="n">rio</span><span class="o">-</span><span class="n">Empr</span><span class="err">é</span><span class="n">stimo</span> <span class="o">&lt;</span> <span class="mf">1.5</span><span class="p">:</span>
  <span class="n">Classe</span> <span class="o">=</span> <span class="s">'Padrão'</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">Classe</span><span class="o">=</span><span class="s">'diferenciada'</span>
</code></pre></div></div>

<p>Bastante simples, não? Este é um exemplo de um modelo de predições (ou seja, exemplo de um agente inteligente). Este é também um exemplo de um modelo consistente com o <em>dataset</em>. Um modelo consistente com o <em>dataset</em> é aquele que depois de aprendido consegue classificar os <em>datapoints</em> contidos no <em>dataset</em> com 100% de acurácia (i.e., sem cometer erros). Observe também que o modelo não faz uso de todas as <em>features</em> apresentadas e que a  <em>feature</em> utilizada é uma <em>feature</em> derivada<sup>2</sup>. Uma feature derivada é uma feature que pode ser obtida a partir de duas ou mais features. No exemplo do modelo acima, <code class="highlighter-rouge">Proporção Salário-Empréstimo</code> pode ser obtida através de features <code class="highlighter-rouge">Salário</code> e <code class="highlighter-rouge">Empréstimo</code> (que não foram exibidas na tabela).</p>

<p>Agora, vamos dificultar as coisas. Suponhamos o <em>dataset</em> contido na Tabela 4.</p>

<p>INCLUIR TABELA</p>

<p>Após uma análise minuciosa deste <em>dataset</em>, podemos propor o algoritmo abaixo (demonstrado utilizando a linguagem <em>python</em>):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">Propor</span><span class="err">çã</span><span class="n">o</span> <span class="n">Sal</span><span class="err">á</span><span class="n">rio</span><span class="o">-</span><span class="n">Empr</span><span class="err">é</span><span class="n">stimo</span> <span class="o">&lt;</span> <span class="mf">1.5</span><span class="p">:</span>
  <span class="n">classe</span> <span class="o">=</span> <span class="s">'diferenciada'</span>
<span class="k">elif</span> <span class="n">Propor</span><span class="err">çã</span><span class="n">o</span> <span class="n">Sal</span><span class="err">á</span><span class="n">rio</span><span class="o">-</span><span class="n">Empr</span><span class="err">é</span><span class="n">stimo</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
  <span class="n">classe</span> <span class="o">=</span><span class="s">'padrão'</span>
<span class="k">elif</span> <span class="n">idade</span>  <span class="o">&lt;</span> <span class="mi">40</span> <span class="ow">and</span> <span class="n">profiss</span><span class="err">ã</span><span class="n">o</span> <span class="o">==</span> <span class="s">'indústria'</span><span class="p">:</span>
  <span class="n">classe</span> <span class="o">=</span> <span class="s">'padrão'</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">classe</span> <span class="o">=</span> <span class="s">'diferenciada'</span>
</code></pre></div></div>

<p>De certa maneira, a extração das regras ficou mais complicada. Imaginemos o caso de um <em>dataset</em> com dezenas de <em>features</em> e milhares de <em>datapoints</em>. A tarefa de extrair as regras torna-se quase que humanamente impossível de realizar. São nestes casos mais complexos que o “brilho” do <em>machine learning</em> aparece. Enquanto para nós seres humanos a tarefa deve certamente demorar dias ou mesmo semanas, um computador pode gerar um modelo em poucos minutos!</p>

<h2 id="2---como-o-machine-learning-funciona">2 - Como o <em>machine learning</em> funciona</h2>

<p>O aprendizado de um modelo de <em>machine learning</em> pode ser visto como um <strong>processo de busca</strong>. Este processo conduz uma busca pelo modelo que melhor captura as relações entre as <em>features</em> e o <em>target</em>. Ou seja, busca pelo modelo capaz de gerar predições corretas para <em>query</em> que ele recebe como entrada.</p>

<p>A forma mais fácil e eficaz para gerar um modelo é buscar dentre os modelos possíveis por aqueles <strong>modelos que sejam “consistentes”</strong> com os <em>datapoints</em>. No entanto, para maioria dos casos, um <em>dataset</em> é apenas uma amostra do número total de <em>datapoints</em> possíveis quando consideramos as possibilidades de combinações dos valores das <em>features</em>. Por exemplo: se uma das <em>features</em> for contínua, temos uma infinita possibilidade de combinações! Por isso, dizemos que o <em>machine learning</em> é um <strong>problema mal-posto</strong>.</p>

<p>Vamos ilustrar a ideia de consistência e imperfeição com um exemplo. Imaginemos que uma rede de supermercados nos contratou para desenvolver um modelo de <em>machine learning</em> para realizar predições sobre seus consumidores. Estas predições devem classificar os consumidores nos grupos <code class="highlighter-rouge">Famílias</code>, <code class="highlighter-rouge">Casais sem filhos</code> e <code class="highlighter-rouge">Solteiros</code>.</p>

<p>Esta rede de supermercados está disposta a lhe entregar um dataset com três <em>features</em> binárias que podem assumir os valores ${True; False}$. Como três <em>features</em> binárias produzem um total de $2^3=8$ combinações, antes de olharmos para o dataset decidimos construir uma tabela com todas as possíveis combinações destas features. Estas combinações estão reproduzidas na Tabela 5.</p>

<p>INCLUIR TABELA</p>

<p>Quando passamos a considerar os valores para o <code class="highlighter-rouge">Grupo</code> sem termos recebido os valores corretos para o <em>target</em> de cada datapoint, o número de combinações diferentes para o <em>dataset</em> sobe para 6561! A partir dessas combinações que consideram o <em>target</em>, podemos procurar por uma combinação que possa servir como modelo para fazer predições sobre os consumidores do mercado. Uma amostra destas combinações está disponível na Tabela 6.</p>

<p>INCLUIR TABELA</p>

<p>Suponhamos então que a rede de supermercados conduziu uma pesquisa entre seus consumidores e que o número de respostas obtido foi baixo. Apenas cinco <em>datapoints</em> foram obtidos conforme demonstrado na Tabela 7.</p>

<p>Se considerarmos os <em>datapoints</em> obtidos pela rede de supermercados, podemos eliminar combinações as quais possuem o target <code class="highlighter-rouge">Grupo</code> diferentes dos valores reais obtidos, como demonstrado na Tabela 8. As combinações restantes são aquelas chamadas de consistentes com o <em>dataset</em> da Tabela 7. Em outras palavras, estas combinações restantes conseguem produzir a resposta correta para cada <em>datapoint</em> do dataset.</p>

<p>Entretanto, ainda temos um problema: das 8 possíveis combinações das <em>features</em> binárias, apenas 5 foram obtidas e, por isso, temos três combinações que nunca foram vistas! Se olharmos novamente para a Tabela 8, as combinações $\mathbb{M}_2$,	$\mathbb{M}_4$ e $\mathbb{M}_5$ são combinações consistentes com o <em>dataset</em> e ao mesmo tempo divergem quanto ao <code class="highlighter-rouge">Grupo</code> que deve ser atribuído aos três casos que não foram vistos. Qual destas três combinações devemos escolher como sendo o modelo final? É exatamente pelo fato de podermos obter mais de um modelo consistente com o <em>dataset</em> que dizemos que o <em>machine learning</em> é um problema mal-posto, pois não há uma solução para esse problema!</p>

<p>Consistência pode ser interpretada como uma forma de <strong>memorização</strong> por parte do modelo. Contudo, os <em>datapoints</em> em um dataset podem conter diversas formas de ruídos, como por exemplo preenchimentos incorretos de valores, valores faltando, até mesmo exceções onde o valor é de fato correto mas tão incomum que parece estar incorreto. Nestes casos, a memorização torna-se uma característica indesejada para um modelo de <em>machine learning</em>.</p>

<p>Ao mesmo tempo que buscamos um modelo consistente, procuramos também um modelo que seja capaz de <strong>generalizar além dos dados</strong>. Um modelo com esta característica é capaz de fazer predições corretas mesmo na presença de <em>datapoints</em> com ruído. Ou seja, este modelo que é capaz de generalizar além do <em>dataset</em> não é influenciado pelo ruído nos dados. Sendo assim, que critérios devemos utilizar para selecionar este modelo?</p>

<p>O <em>machine learning</em> faz uma série de suposições que auxiliam a definir os critérios de seleção de um modelo. Estas suposições são chamados viéses indutivos (do Inglês <strong><em>inductive bias</em></strong>):</p>

<p>    a.viés de restrição (<strong><em>restriction bias</em></strong>): limita o tipo de modelo que será aprendido.</p>

<p>    b. viés de preferência (<strong><em>preference bias</em></strong>): limita o algoritmo para que prefira alguns tipos de modelo em detrimento a outros modelos.</p>

<p>Por exemplo, consideremos o Iterative Dichotomizer 3 - (ID3), o algoritmo padrão para métodos baseados em informação<sup>3</sup>. Este algoritmo possui um <em>restriction bias</em> que o limita a aprender um modelo em formato de árvore que codifica em cada galho um “teste” em uma determinada <em>feature</em> enquanto o seu <em>preference bias</em> limita-o a buscar pela árvore que contenha o menor número possível de níveis.</p>

<h3 id="21---o-que-pode-dar-errado-com-o-machine-learning">2.1 - O que pode dar errado com o <em>machine learning</em>?</h3>

<p>Até agora vimos que o <em>machine learning</em> pode ser bastante útil para criarmos agentes inteligentes que podem ser úteis em alguns tipos de problemas. Vimos também que devido ao efeito do <em>inductive bias</em>, modelos podem aprender a generalizar além do <em>dataset</em>. No entanto, se escolhermos o <em>inductive bias</em> errado, o modelo aprendido poderá apresentar dois tipos de problemas: <em>underfitting</em> e <em>overfitting</em>.</p>

<p><em>Underfitting</em> ocorre quando o modelo aprendido através do <em>inductive bias</em> é muito simples para capturar as relações entre <em>features</em> e <em>targets</em>. <em>Overfitting</em>, ao contrário, ocorre quando o modelo aprendido através do <em>inductive bias</em> é demasiado complexo para capturar as relações entre <em>features</em> e <em>targets</em>. A Figura 3 exibe um exemplo de <em>underfitting</em> e <em>overfitting</em>.</p>

<h2 id="3---resumo">3 - Resumo</h2>

<p>Em resumo, um algoritmo de <em>machine learning</em> aprende a relação entre <em>features</em> e <em>targets</em> a partir de exemplos contidos em um <em>dataset</em>. Além disso, <em>machine learning</em> é considerado um problema malposto devido a quatros fatores: a) precisa generalizar a além do <em>dataset</em> que por sua vez é apenas uma amostra; b) precisa de um conjunto de suposições que são necessárias para o aprendizado (<em>inductive bias</em>); c) <em>underfitting</em>; e d) <em>overfitting</em>. Encontrar o balanço entre complexidade e simplicidade é uma forma de arte do <em>machine learning</em> e, também, a parte mais difícil de prática.</p>


          
        </div>
      </div>
    </div>
  </div>

</body>
</html>
